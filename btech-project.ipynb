{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T07:28:41.351231Z",
     "iopub.status.busy": "2022-03-07T07:28:41.350507Z",
     "iopub.status.idle": "2022-03-07T07:28:49.066557Z",
     "shell.execute_reply": "2022-03-07T07:28:49.065471Z",
     "shell.execute_reply.started": "2022-03-07T07:28:41.351107Z"
    },
    "id": "B2ZRpPRL7iRX",
    "outputId": "cad3b0d9-6919-490e-80dc-fa0a7db09c3d"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Requirement already satisfied: tqdm in c:\\users\\91952\\anaconda3\\lib\\site-packages (4.47.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T10:37:06.313144Z",
     "iopub.status.busy": "2022-03-07T10:37:06.312778Z",
     "iopub.status.idle": "2022-03-07T10:37:12.177691Z",
     "shell.execute_reply": "2022-03-07T10:37:12.176769Z",
     "shell.execute_reply.started": "2022-03-07T10:37:06.313046Z"
    },
    "id": "ICUVtLpJr9PP"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import random \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T10:37:12.180790Z",
     "iopub.status.busy": "2022-03-07T10:37:12.180095Z",
     "iopub.status.idle": "2022-03-07T10:37:12.191191Z",
     "shell.execute_reply": "2022-03-07T10:37:12.190049Z",
     "shell.execute_reply.started": "2022-03-07T10:37:12.180749Z"
    },
    "id": "GGdnOfPAr9PA",
    "outputId": "fb8cef8b-10e7-49c1-9931-be07818ff528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Projects\\\\BTech-Project\\\\audio\\\\'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.getcwd()\n",
    "data_path = os.path.join(data_path, \"audio\\\\\")\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T10:37:12.193813Z",
     "iopub.status.busy": "2022-03-07T10:37:12.192974Z",
     "iopub.status.idle": "2022-03-07T10:37:12.224416Z",
     "shell.execute_reply": "2022-03-07T10:37:12.223733Z",
     "shell.execute_reply.started": "2022-03-07T10:37:12.193769Z"
    },
    "id": "e9W7lpl1r9PE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = ['filename', 'label']\n",
    "dcase2016 = pd.read_csv('./meta.txt', sep='\\t', encoding='ASCII', names=columns)\n",
    "# dcase2016['filename'] = dcase2016['filename'].str.replace('audio','audio/audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T07:28:51.134316Z",
     "iopub.status.busy": "2022-03-07T07:28:51.134053Z",
     "iopub.status.idle": "2022-03-07T07:28:51.155563Z",
     "shell.execute_reply": "2022-03-07T07:28:51.154632Z",
     "shell.execute_reply.started": "2022-03-07T07:28:51.134285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio/a001_0_30.wav</td>\n",
       "      <td>residential_area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio/a001_120_150.wav</td>\n",
       "      <td>residential_area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio/a001_150_180.wav</td>\n",
       "      <td>residential_area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio/a001_30_60.wav</td>\n",
       "      <td>residential_area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio/a001_60_90.wav</td>\n",
       "      <td>residential_area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>audio/b116_180_210.wav</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>audio/b116_240_270.wav</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>audio/b116_30_60.wav</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>audio/b116_60_90.wav</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>audio/b116_90_120.wav</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1170 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename             label\n",
       "0        audio/a001_0_30.wav  residential_area\n",
       "1     audio/a001_120_150.wav  residential_area\n",
       "2     audio/a001_150_180.wav  residential_area\n",
       "3       audio/a001_30_60.wav  residential_area\n",
       "4       audio/a001_60_90.wav  residential_area\n",
       "...                      ...               ...\n",
       "1165  audio/b116_180_210.wav            office\n",
       "1166  audio/b116_240_270.wav            office\n",
       "1167    audio/b116_30_60.wav            office\n",
       "1168    audio/b116_60_90.wav            office\n",
       "1169   audio/b116_90_120.wav            office\n",
       "\n",
       "[1170 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcase2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T07:28:51.157828Z",
     "iopub.status.busy": "2022-03-07T07:28:51.157475Z",
     "iopub.status.idle": "2022-03-07T07:28:51.196037Z",
     "shell.execute_reply": "2022-03-07T07:28:51.194893Z",
     "shell.execute_reply.started": "2022-03-07T07:28:51.157782Z"
    }
   },
   "outputs": [],
   "source": [
    "# columns = ['filename', 'label', 'code']\n",
    "# dcase2017 = pd.read_csv('../input/dcase2016/meta1.txt', sep='\\t', encoding='ASCII', names=columns)\n",
    "# dcase2017.drop(['code'], axis = 1, inplace=True)\n",
    "# dcase2017['filename'] = dcase2017['filename'].str.replace('audio','audio1/audio')\n",
    "# dcase2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T07:28:51.19848Z",
     "iopub.status.busy": "2022-03-07T07:28:51.198143Z",
     "iopub.status.idle": "2022-03-07T07:28:51.205295Z",
     "shell.execute_reply": "2022-03-07T07:28:51.204214Z",
     "shell.execute_reply.started": "2022-03-07T07:28:51.198433Z"
    },
    "id": "XsqavCF9r9PH",
    "outputId": "2d6be1ee-eefa-48b8-e339-ba5dae6d5fa2"
   },
   "outputs": [],
   "source": [
    "# data_df = pd.concat([dcase2016, dcase2017], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T10:37:12.226990Z",
     "iopub.status.busy": "2022-03-07T10:37:12.226577Z",
     "iopub.status.idle": "2022-03-07T10:37:12.233231Z",
     "shell.execute_reply": "2022-03-07T10:37:12.232112Z",
     "shell.execute_reply.started": "2022-03-07T10:37:12.226951Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('./segmented_audio/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T10:37:12.235561Z",
     "iopub.status.busy": "2022-03-07T10:37:12.234868Z",
     "iopub.status.idle": "2022-03-07T10:37:12.260133Z",
     "shell.execute_reply": "2022-03-07T10:37:12.259490Z",
     "shell.execute_reply.started": "2022-03-07T10:37:12.235520Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def segment_audio():\n",
    "    \n",
    "    filename = []\n",
    "    label = []\n",
    "    for index_num,row in tqdm(dcase2016.iterrows()):\n",
    "    \n",
    "        fname = os.path.basename(row['filename']).split('.')[0]\n",
    "        \n",
    "        filepath = data_path + fname + \".wav\"\n",
    "        myaudio = AudioSegment.from_file(filepath, \"wav\") \n",
    "        chunk_length_ms = 10000        # in millisec\n",
    "        chunks = make_chunks(myaudio, chunk_length_ms) \n",
    "\n",
    "        name = os.path.basename(filepath).split('.')[0]\n",
    "\n",
    "        #Export all of the individual chunks as wav files\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_name = \"./segmented_audio/\"+name+\"_{0}.wav\".format(i)\n",
    "            chunk.export(chunk_name, format=\"wav\")\n",
    "\n",
    "            # create dataset\n",
    "            filename.append(\"segmented_audio/\"+name+\"_{0}.wav\".format(i))\n",
    "            f = \"audio/\"+name+\".wav\"\n",
    "            label.append(dcase2016.loc[dcase2016['filename']==f, 'label'].values[0])\n",
    "\n",
    "    return filename, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T10:37:12.261633Z",
     "iopub.status.busy": "2022-03-07T10:37:12.261355Z",
     "iopub.status.idle": "2022-03-07T11:08:20.428808Z",
     "shell.execute_reply": "2022-03-07T11:08:20.427916Z",
     "shell.execute_reply.started": "2022-03-07T10:37:12.261596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1170it [37:45,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "filename, label = segment_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T11:09:00.664529Z",
     "iopub.status.busy": "2022-03-07T11:09:00.664249Z",
     "iopub.status.idle": "2022-03-07T11:28:00.494861Z",
     "shell.execute_reply": "2022-03-07T11:28:00.490031Z",
     "shell.execute_reply.started": "2022-03-07T11:09:00.664498Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"segmented_audio\", 'zip', \"./segmented_audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-07T11:28:00.495652Z",
     "iopub.status.idle": "2022-03-07T11:28:00.495954Z",
     "shell.execute_reply": "2022-03-07T11:28:00.495818Z",
     "shell.execute_reply.started": "2022-03-07T11:28:00.495798Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize data of lists.\n",
    "data = {'filename':filename,\n",
    "        'label':label}\n",
    " \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('segmented_audio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T05:48:30.225454Z",
     "iopub.status.busy": "2022-03-07T05:48:30.22492Z",
     "iopub.status.idle": "2022-03-07T05:48:30.241678Z",
     "shell.execute_reply": "2022-03-07T05:48:30.241005Z",
     "shell.execute_reply.started": "2022-03-07T05:48:30.225372Z"
    }
   },
   "outputs": [],
   "source": [
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T05:48:30.243904Z",
     "iopub.status.busy": "2022-03-07T05:48:30.243359Z",
     "iopub.status.idle": "2022-03-07T05:48:32.507972Z",
     "shell.execute_reply": "2022-03-07T05:48:32.507197Z",
     "shell.execute_reply.started": "2022-03-07T05:48:30.243858Z"
    },
    "id": "Ftxgx8S4r9PQ",
    "outputId": "f1a7c455-ba6b-49f9-9465-ad85a27ad4ee"
   },
   "outputs": [],
   "source": [
    "data, fs = librosa.load(data_path + data_df['filename'][0])\n",
    "librosa.display.waveplot(data, sr=fs)\n",
    "print(fs)\n",
    "print(fs*30)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "ipd.Audio(data_path + data_df['filename'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T05:48:32.509402Z",
     "iopub.status.busy": "2022-03-07T05:48:32.509122Z",
     "iopub.status.idle": "2022-03-07T05:48:32.528839Z",
     "shell.execute_reply": "2022-03-07T05:48:32.528082Z",
     "shell.execute_reply.started": "2022-03-07T05:48:32.509363Z"
    },
    "id": "UWmVRbF5r9PT",
    "outputId": "1602de87-685c-4a26-8598-2f0eae57bf19"
   },
   "outputs": [],
   "source": [
    "data_df['filename'][0]\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T05:48:32.532239Z",
     "iopub.status.busy": "2022-03-07T05:48:32.531818Z",
     "iopub.status.idle": "2022-03-07T05:48:32.541319Z",
     "shell.execute_reply": "2022-03-07T05:48:32.540766Z",
     "shell.execute_reply.started": "2022-03-07T05:48:32.532206Z"
    },
    "id": "REvifJMLr9Pc",
    "outputId": "8fc1d45a-5f25-4ec2-c125-b1a7dd9a068d"
   },
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "# Check for null values\n",
    "\n",
    "data_df.isnull().any()\n",
    "# false implies no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T05:48:32.543347Z",
     "iopub.status.busy": "2022-03-07T05:48:32.542786Z",
     "iopub.status.idle": "2022-03-07T05:48:32.565031Z",
     "shell.execute_reply": "2022-03-07T05:48:32.56449Z",
     "shell.execute_reply.started": "2022-03-07T05:48:32.543306Z"
    },
    "id": "aTZCtVkur9Pi",
    "outputId": "7a33bd1a-b2ea-44b9-b88b-78a593025bce"
   },
   "outputs": [],
   "source": [
    "labels_coded = pd.get_dummies(data_df['label'])\n",
    "labels_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T05:48:32.566622Z",
     "iopub.status.busy": "2022-03-07T05:48:32.566208Z",
     "iopub.status.idle": "2022-03-07T05:48:32.57228Z",
     "shell.execute_reply": "2022-03-07T05:48:32.571668Z",
     "shell.execute_reply.started": "2022-03-07T05:48:32.566591Z"
    },
    "id": "eOUnRAfDr9Pj"
   },
   "outputs": [],
   "source": [
    "data_df = pd.concat([data_df, labels_coded], axis=1)\n",
    "dataset = data_df.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T03:24:49.897894Z",
     "iopub.status.busy": "2022-03-03T03:24:49.897635Z",
     "iopub.status.idle": "2022-03-03T03:24:50.082459Z",
     "shell.execute_reply": "2022-03-03T03:24:50.08151Z",
     "shell.execute_reply.started": "2022-03-03T03:24:49.897866Z"
    },
    "id": "L9KzyobVr9Pn",
    "outputId": "ae66cf37-beda-47c5-8bc2-83f8eeeb4361"
   },
   "outputs": [],
   "source": [
    "labels = dataset.columns[1:] #getting labels name except image_id\n",
    "labels =  labels\n",
    "print(\"Labels: \",labels)\n",
    "\n",
    "sizes = list(dataset.iloc[:,1:].sum())\n",
    "print(\"Sizes: \",sizes)\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(sizes, labels = labels)\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T13:15:43.517625Z",
     "iopub.status.busy": "2022-02-24T13:15:43.517358Z",
     "iopub.status.idle": "2022-02-24T13:15:44.16929Z",
     "shell.execute_reply": "2022-02-24T13:15:44.168561Z",
     "shell.execute_reply.started": "2022-02-24T13:15:43.517594Z"
    },
    "id": "_mVSMJOcr9Pp",
    "outputId": "371ca23e-a9bd-4f61-b48f-8c0a67285844"
   },
   "outputs": [],
   "source": [
    "# FFT -> power spectrum\n",
    "# perform Fourier transform\n",
    "signal = data\n",
    "fft = np.fft.fft(signal)\n",
    "\n",
    "# calculate abs values on complex numbers to get magnitude\n",
    "spectrum = np.abs(fft)\n",
    "\n",
    "# create frequency variable\n",
    "f = np.linspace(0, fs, len(spectrum))\n",
    "\n",
    "# take half of the spectrum and frequency\n",
    "left_spectrum = spectrum[:int(len(spectrum)/2)]\n",
    "left_f = f[:int(len(spectrum)/2)]\n",
    "\n",
    "# plot spectrum\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.plot(left_f, left_spectrum, alpha=0.4)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Power spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-18T06:09:15.235786Z",
     "iopub.status.busy": "2022-02-18T06:09:15.233647Z",
     "iopub.status.idle": "2022-02-18T06:09:17.897109Z",
     "shell.execute_reply": "2022-02-18T06:09:17.896455Z",
     "shell.execute_reply.started": "2022-02-18T06:09:15.235745Z"
    },
    "id": "RRsqUN77r9Pq",
    "outputId": "c14d317a-f987-4210-8511-6fc98c94344f"
   },
   "outputs": [],
   "source": [
    "# STFT -> spectrogram\n",
    "FIG_SIZE=(10,15)\n",
    "hop_length = 512 # in num. of samples\n",
    "n_fft = 2048 # window in num. of samples\n",
    "\n",
    "# calculate duration hop length and window in seconds\n",
    "hop_length_duration = float(hop_length)/fs\n",
    "n_fft_duration = float(n_fft)/fs\n",
    "\n",
    "print(\"STFT hop length duration is: {}s\".format(hop_length_duration))\n",
    "print(\"STFT window duration is: {}s\".format(n_fft_duration))\n",
    "\n",
    "# perform stft\n",
    "stft = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "# calculate abs values on complex numbers to get magnitude\n",
    "spectrogram = np.abs(stft)\n",
    "\n",
    "# display spectrogram\n",
    "plt.figure(figsize=FIG_SIZE)\n",
    "librosa.display.specshow(spectrogram, sr=fs, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Spectrogram\")\n",
    "\n",
    "# apply logarithm to cast amplitude to Decibels\n",
    "log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
    "log_spectrogram = np.array(log_spectrogram)\n",
    "print(np.shape(log_spectrogram))\n",
    "\n",
    "plt.figure(figsize=FIG_SIZE)\n",
    "librosa.display.specshow(log_spectrogram, sr=fs, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Spectrogram (dB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T13:16:17.031122Z",
     "iopub.status.busy": "2022-02-24T13:16:17.030608Z",
     "iopub.status.idle": "2022-02-24T13:16:17.363527Z",
     "shell.execute_reply": "2022-02-24T13:16:17.36286Z",
     "shell.execute_reply.started": "2022-02-24T13:16:17.031083Z"
    },
    "id": "mPPA8xZer9Pq",
    "outputId": "f88b4f7d-a9e4-4c78-de54-5c9827650921"
   },
   "outputs": [],
   "source": [
    "# MFCCs\n",
    "FIG_SIZE=(10,15)\n",
    "hop_length = 512 # in num. of samples\n",
    "n_fft = 2048 # window in num. of samples\n",
    "# extract 13 MFCCs\n",
    "MFCCs = librosa.feature.mfcc(signal, fs, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "\n",
    "# display MFCCs\n",
    "plt.figure(figsize=FIG_SIZE)\n",
    "librosa.display.specshow(MFCCs, sr=fs, hop_length=hop_length)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"MFCC coefficients\")\n",
    "plt.colorbar()\n",
    "plt.title(\"MFCCs\")\n",
    "\n",
    "# show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T13:16:21.408948Z",
     "iopub.status.busy": "2022-02-24T13:16:21.408691Z",
     "iopub.status.idle": "2022-02-24T13:16:21.414715Z",
     "shell.execute_reply": "2022-02-24T13:16:21.413845Z",
     "shell.execute_reply.started": "2022-02-24T13:16:21.408916Z"
    },
    "id": "2li-zclvr9Pr",
    "outputId": "2c2910ff-9094-4410-8e2a-fe127ee49d25"
   },
   "outputs": [],
   "source": [
    "MFCCs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-24T16:42:59.404871Z",
     "iopub.status.busy": "2022-01-24T16:42:59.404619Z",
     "iopub.status.idle": "2022-01-24T16:42:59.411653Z",
     "shell.execute_reply": "2022-01-24T16:42:59.41082Z",
     "shell.execute_reply.started": "2022-01-24T16:42:59.404842Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spectrogram\n",
    "\n",
    "def get_spectrogram(waveform):\n",
    "    # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "    input_len = 660000\n",
    "    waveform = waveform[:input_len]\n",
    "    zero_padding = tf.zeros(\n",
    "        [input_len] - tf.shape(waveform),\n",
    "        dtype=tf.float32)\n",
    "    \n",
    "    waveform = tf.cast(waveform, dtype=tf.float32)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio\n",
    "    # clips are of the same length.\n",
    "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    # Convert the waveform to a spectrogram via a STFT.\n",
    "    spectrogram = tf.signal.stft(\n",
    "        equal_length, frame_length=550, frame_step=275)\n",
    "    # Obtain the magnitude of the STFT.\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    # Add a `channels` dimension, so that the spectrogram can be used\n",
    "    # as image-like input data with convolution layers (which expect\n",
    "    # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "    spectrogram = spectrogram[..., tf.newaxis]\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-24T16:42:59.974934Z",
     "iopub.status.busy": "2022-01-24T16:42:59.974241Z",
     "iopub.status.idle": "2022-01-24T16:42:59.98322Z",
     "shell.execute_reply": "2022-01-24T16:42:59.981674Z",
     "shell.execute_reply.started": "2022-01-24T16:42:59.974896Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_spectrogram(spectrogram, ax):\n",
    "    if len(spectrogram.shape) > 2:\n",
    "        assert len(spectrogram.shape) == 3\n",
    "        spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "    # Convert the frequencies to log scale and transpose, so that the time is\n",
    "    # represented on the x-axis (columns).\n",
    "    # Add an epsilon to avoid taking a log of zero.\n",
    "    log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "    height = log_spec.shape[0]\n",
    "    width = log_spec.shape[1]\n",
    "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "    Y = range(height)\n",
    "    ax.pcolormesh(X, Y, log_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T12:04:24.086911Z",
     "iopub.status.busy": "2022-03-03T12:04:24.086106Z",
     "iopub.status.idle": "2022-03-03T12:04:24.093065Z",
     "shell.execute_reply": "2022-03-03T12:04:24.092159Z",
     "shell.execute_reply.started": "2022-03-03T12:04:24.086872Z"
    },
    "id": "PWjwkljyr9Pr"
   },
   "outputs": [],
   "source": [
    "n_mfcc = 13\n",
    "def features_extractor(file):\n",
    "    data, fs = librosa.load(file)\n",
    "    mfcc_features = librosa.feature.mfcc(data, sr=fs, n_mfcc=n_mfcc)\n",
    "    mfcc_features = mfcc_features[:,:431]\n",
    "    \n",
    "#     delta_mfcc = librosa.feature.delta(mfcc_features)\n",
    "#     delta_mfcc = np.mean(delta_mfcc,axis=0)\n",
    "\n",
    "#     delta2_mfcc = librosa.feature.delta(mfcc_features, order=2)\n",
    "#     delta2_mfcc = np.mean(delta2_mfcc,axis=0)\n",
    "\n",
    "#     mfcc_features = np.mean(mfcc_features,axis=0)\n",
    "#     mfccs_scaled_features = np.row_stack((mfcc_features, delta_mfcc, delta2_mfcc))\n",
    "    \n",
    "    return mfcc_features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T12:04:24.447208Z",
     "iopub.status.busy": "2022-03-03T12:04:24.446635Z",
     "iopub.status.idle": "2022-03-03T12:04:24.881062Z",
     "shell.execute_reply": "2022-03-03T12:04:24.880233Z",
     "shell.execute_reply.started": "2022-03-03T12:04:24.447171Z"
    },
    "id": "OapW4Lpwr9Ps",
    "outputId": "23a3201d-f1ab-43a6-ed64-f77eb093091b"
   },
   "outputs": [],
   "source": [
    "mf = features_extractor(\"../input/dcase2016/audio1/audio/a001_0_10.wav\")\n",
    "mf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T12:04:25.160302Z",
     "iopub.status.busy": "2022-03-03T12:04:25.160071Z",
     "iopub.status.idle": "2022-03-03T13:07:07.625077Z",
     "shell.execute_reply": "2022-03-03T13:07:07.62204Z",
     "shell.execute_reply.started": "2022-03-03T12:04:25.160275Z"
    },
    "id": "jZXw55Bhr9Ps",
    "outputId": "ae185278-a25e-4cc8-e57d-355573067165"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "### iterate through every audio file and extract features\n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "\n",
    "for index_num,row in tqdm(dataset.iterrows()):\n",
    "    \n",
    "    file_name = data_path + row['filename']\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_features.append(data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T13:07:07.627504Z",
     "iopub.status.busy": "2022-03-03T13:07:07.627156Z",
     "iopub.status.idle": "2022-03-03T13:07:07.963425Z",
     "shell.execute_reply": "2022-03-03T13:07:07.962624Z",
     "shell.execute_reply.started": "2022-03-03T13:07:07.627464Z"
    },
    "id": "fpDwqi29buyu",
    "outputId": "6c3cd1fc-eac4-4b1e-c2e0-20c55dbc1a36"
   },
   "outputs": [],
   "source": [
    "np.array(extracted_features)\n",
    "type(extracted_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T13:07:07.973539Z",
     "iopub.status.busy": "2022-03-03T13:07:07.972931Z",
     "iopub.status.idle": "2022-03-03T13:07:08.204542Z",
     "shell.execute_reply": "2022-03-03T13:07:08.2033Z",
     "shell.execute_reply.started": "2022-03-03T13:07:07.973489Z"
    },
    "id": "WnXBeGC0AaWK"
   },
   "outputs": [],
   "source": [
    "np.save('mfcc_431_13_2016_2017.npy', extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:24.51395Z",
     "iopub.status.busy": "2022-03-06T04:08:24.513583Z",
     "iopub.status.idle": "2022-03-06T04:08:26.44083Z",
     "shell.execute_reply": "2022-03-06T04:08:26.440017Z",
     "shell.execute_reply.started": "2022-03-06T04:08:24.513917Z"
    }
   },
   "outputs": [],
   "source": [
    "extracted_features = np.load('../input/mfcc-431-13-2016-17/mfcc_431_13_2016_2017.npy')\n",
    "type(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:31.808529Z",
     "iopub.status.busy": "2022-03-06T04:08:31.808185Z",
     "iopub.status.idle": "2022-03-06T04:08:37.194041Z",
     "shell.execute_reply": "2022-03-06T04:08:37.192949Z",
     "shell.execute_reply.started": "2022-03-06T04:08:31.808493Z"
    },
    "id": "C0E-jc0mJW74"
   },
   "outputs": [],
   "source": [
    "f = extracted_features.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:37.197016Z",
     "iopub.status.busy": "2022-03-06T04:08:37.196503Z",
     "iopub.status.idle": "2022-03-06T04:08:39.915677Z",
     "shell.execute_reply": "2022-03-06T04:08:39.914668Z",
     "shell.execute_reply.started": "2022-03-06T04:08:37.196967Z"
    },
    "id": "J9Vz22FCr9Pt",
    "outputId": "62ec56b2-d18a-4f90-848b-5ab6dbb3a6d5"
   },
   "outputs": [],
   "source": [
    "dataset.insert(loc=1, column='features', value=f)\n",
    "# dataset.to_csv('dcase2016.csv')\n",
    "# type(dataset.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:39.918224Z",
     "iopub.status.busy": "2022-03-06T04:08:39.917854Z",
     "iopub.status.idle": "2022-03-06T04:08:39.931052Z",
     "shell.execute_reply": "2022-03-06T04:08:39.929988Z",
     "shell.execute_reply.started": "2022-03-06T04:08:39.918169Z"
    },
    "id": "lEs1vfh5tIuT",
    "outputId": "d0081989-b64d-4b90-e371-5e73cd82b40e"
   },
   "outputs": [],
   "source": [
    "# new_data = pd.read_csv('./dcase2016.csv', index_col=0)\n",
    "# type(new_data.iloc[0,1])\n",
    "# new_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:39.934333Z",
     "iopub.status.busy": "2022-03-06T04:08:39.933887Z",
     "iopub.status.idle": "2022-03-06T04:08:40.174161Z",
     "shell.execute_reply": "2022-03-06T04:08:40.173131Z",
     "shell.execute_reply.started": "2022-03-06T04:08:39.934288Z"
    },
    "id": "qZxhIV5ww4df",
    "outputId": "e510827a-43bf-4e49-cfc3-9b22f1d368b4"
   },
   "outputs": [],
   "source": [
    "dataset.head()\n",
    "# dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:40.176104Z",
     "iopub.status.busy": "2022-03-06T04:08:40.175799Z",
     "iopub.status.idle": "2022-03-06T04:08:47.471226Z",
     "shell.execute_reply": "2022-03-06T04:08:47.470157Z",
     "shell.execute_reply.started": "2022-03-06T04:08:40.176064Z"
    },
    "id": "IWklkFBVcfon",
    "outputId": "6de4b2e3-0193-4508-8a1d-b72fce8a3b3f"
   },
   "outputs": [],
   "source": [
    "dataset['features'] = dataset['features'].apply(lambda x: np.array(x))\n",
    "# dataset['features'] = dataset['features'].apply(lambda x: np.mean(x, axis=1)) \n",
    "# dataset['features'] = dataset['features'].apply(lambda x: np.delete(x, [1,2], axis=1))\n",
    "\n",
    "type(dataset['features'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:47.473301Z",
     "iopub.status.busy": "2022-03-06T04:08:47.472823Z",
     "iopub.status.idle": "2022-03-06T04:08:47.481637Z",
     "shell.execute_reply": "2022-03-06T04:08:47.480459Z",
     "shell.execute_reply.started": "2022-03-06T04:08:47.473205Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['features'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:47.483885Z",
     "iopub.status.busy": "2022-03-06T04:08:47.483549Z",
     "iopub.status.idle": "2022-03-06T04:08:47.650588Z",
     "shell.execute_reply": "2022-03-06T04:08:47.649765Z",
     "shell.execute_reply.started": "2022-03-06T04:08:47.48384Z"
    },
    "id": "DqLnqDtZr9Pt"
   },
   "outputs": [],
   "source": [
    "# For supervised\n",
    "X = dataset.iloc[:, 1]\n",
    "y = dataset.iloc[:, 2:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=13572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:33:46.365968Z",
     "iopub.status.busy": "2022-03-03T16:33:46.365338Z",
     "iopub.status.idle": "2022-03-03T16:33:46.572452Z",
     "shell.execute_reply": "2022-03-03T16:33:46.571744Z",
     "shell.execute_reply.started": "2022-03-03T16:33:46.365858Z"
    }
   },
   "outputs": [],
   "source": [
    "# For semi-supervised\n",
    "data_size = dataset.size\n",
    "percent_labelled = 20\n",
    "percent_test = 10\n",
    "\n",
    "X = dataset.iloc[:, 1]\n",
    "y = dataset.iloc[:, 2:]\n",
    "X_unlabelled, X_labelled, X_test = np.split(X.sample(frac=1, random_state=42),[int(.7*len(X)), int(.9*len(X))])\n",
    "y_unlabelled, y_labelled, y_test = np.split(y.sample(frac=1, random_state=42),[int(.7*len(y)), int(.9*len(y))])\n",
    "\n",
    "print(X_unlabelled)\n",
    "print(y_unlabelled)\n",
    "print(y_labelled)\n",
    "# print(y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:33:46.574019Z",
     "iopub.status.busy": "2022-03-03T16:33:46.573625Z",
     "iopub.status.idle": "2022-03-03T16:33:46.578215Z",
     "shell.execute_reply": "2022-03-03T16:33:46.577531Z",
     "shell.execute_reply.started": "2022-03-03T16:33:46.573982Z"
    },
    "id": "-cjooU0TmALc"
   },
   "outputs": [],
   "source": [
    "y_labels = pd.concat([y_unlabelled, y_labelled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:33:46.580072Z",
     "iopub.status.busy": "2022-03-03T16:33:46.579623Z",
     "iopub.status.idle": "2022-03-03T16:33:46.59236Z",
     "shell.execute_reply": "2022-03-03T16:33:46.591234Z",
     "shell.execute_reply.started": "2022-03-03T16:33:46.580029Z"
    },
    "id": "QUJ_nzTUr9Pu",
    "outputId": "a9c657dd-5664-4121-9588-130df563083a"
   },
   "outputs": [],
   "source": [
    "# Comment this for supervised\n",
    "\n",
    "X_train = X_unlabelled.append(X_labelled)\n",
    "y_unlabelled.iloc[:,:] = 0\n",
    "y_train = pd.concat([y_unlabelled, y_labelled], axis=0)\n",
    "print(X_train[626])\n",
    "print(y_train.iloc[626,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:33:46.595758Z",
     "iopub.status.busy": "2022-03-03T16:33:46.59548Z",
     "iopub.status.idle": "2022-03-03T16:33:46.599553Z",
     "shell.execute_reply": "2022-03-03T16:33:46.598424Z",
     "shell.execute_reply.started": "2022-03-03T16:33:46.59572Z"
    },
    "id": "UUot6cH5r9Pu"
   },
   "outputs": [],
   "source": [
    "# creating a csv file for modified dataset\n",
    "# df = pd.concat([X, y], axis=1)\n",
    "# df.to_csv('SSL_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:08:56.330864Z",
     "iopub.status.busy": "2022-03-06T04:08:56.330062Z",
     "iopub.status.idle": "2022-03-06T04:08:56.336348Z",
     "shell.execute_reply": "2022-03-06T04:08:56.335104Z",
     "shell.execute_reply.started": "2022-03-06T04:08:56.330824Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 15\n",
    "n_mfcc = dataset['features'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:33:46.611465Z",
     "iopub.status.busy": "2022-03-03T16:33:46.610904Z",
     "iopub.status.idle": "2022-03-03T16:33:46.6179Z",
     "shell.execute_reply": "2022-03-03T16:33:46.616878Z",
     "shell.execute_reply.started": "2022-03-03T16:33:46.611423Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.Dense(256, activation='relu', input_dim=(n_mfcc)))\n",
    "# model.add(keras.layers.Dropout(0.5))\n",
    "# model.add(keras.layers.Dense(128, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.5))\n",
    "# model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.5))\n",
    "# model.add(keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCASE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:09:00.614539Z",
     "iopub.status.busy": "2022-03-06T04:09:00.613786Z",
     "iopub.status.idle": "2022-03-06T04:09:02.29008Z",
     "shell.execute_reply": "2022-03-06T04:09:02.289185Z",
     "shell.execute_reply.started": "2022-03-06T04:09:00.614492Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "# Create DCASE Architecture\n",
    "model = keras.Sequential()\n",
    "inputShape = (13, 1290, 1)\n",
    "model.add(Input(shape=inputShape))\n",
    "model.add(Resizing(149, 149))\n",
    "model.add(Conv2D(32, 5, activation='relu', padding=\"valid\", strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, 3, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, 3, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, 3, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, 3, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, 3, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, 3, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, 3, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(512, 3, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, 1, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(15, 1, activation='relu', padding=\"same\", strides=1))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T05:00:29.326497Z",
     "iopub.status.busy": "2022-02-27T05:00:29.325874Z",
     "iopub.status.idle": "2022-02-27T05:00:29.330755Z",
     "shell.execute_reply": "2022-02-27T05:00:29.329905Z",
     "shell.execute_reply.started": "2022-02-27T05:00:29.326457Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T12:58:27.094087Z",
     "iopub.status.busy": "2022-02-27T12:58:27.093724Z",
     "iopub.status.idle": "2022-02-27T12:58:31.955408Z",
     "shell.execute_reply": "2022-02-27T12:58:31.954656Z",
     "shell.execute_reply.started": "2022-02-27T12:58:27.093981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
    "\n",
    "\n",
    "\n",
    "class SSL_Architecture:\n",
    "    @staticmethod\n",
    "    def build(width, height, classes):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, 1)\n",
    "        chanDim = -1\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (1, height, width)\n",
    "            chanDim = 1\n",
    "\n",
    "        # Build model\n",
    "        model.add(Input(shape=inputShape))\n",
    "        model.add(Resizing(128, 128))\n",
    "        model.add(Conv2D(16, 3, activation='relu', padding='same',use_bias=True,kernel_regularizer =tf.keras.regularizers.l1( l=0.01)))\n",
    "        model.add(Conv2D(32, 3, activation='relu', padding='same',use_bias=True,kernel_regularizer =tf.keras.regularizers.l1( l=0.01)))\n",
    "        model.add(Conv2D(64, 3, activation='relu', padding='same',use_bias=True,kernel_regularizer =tf.keras.regularizers.l1( l=0.01)))\n",
    "        model.add(Conv2D(128, 3, activation='relu', padding='same',use_bias=True,kernel_regularizer =tf.keras.regularizers.l1( l=0.01)))\n",
    "        model.add(MaxPooling2D())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T13:06:28.135997Z",
     "iopub.status.busy": "2022-02-27T13:06:28.135739Z",
     "iopub.status.idle": "2022-02-27T13:06:28.211332Z",
     "shell.execute_reply": "2022-02-27T13:06:28.210645Z",
     "shell.execute_reply.started": "2022-02-27T13:06:28.135966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = keras.Sequential()\n",
    "model.add(Input(shape=(13, 1292)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(9092,activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(4096,activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(2048,activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense( 1024, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T04:54:44.701623Z",
     "iopub.status.busy": "2022-02-27T04:54:44.70107Z",
     "iopub.status.idle": "2022-02-27T04:54:44.760534Z",
     "shell.execute_reply": "2022-02-27T04:54:44.759851Z",
     "shell.execute_reply.started": "2022-02-27T04:54:44.701585Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create the model\n",
    "# model = keras.Sequential()\n",
    "# model.add(Input(shape=n_mfcc))\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(keras.layers.Dense(1024,activation='relu'))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(keras.layers.Dense(512, activation='relu'))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(keras.layers.Dense(256, activation='relu'))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(keras.layers.Dense(128, activation='relu'))\n",
    "# # model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# model.add(keras.layers.Dense(15, activation='softmax'))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T05:00:46.601908Z",
     "iopub.status.busy": "2022-02-27T05:00:46.601153Z",
     "iopub.status.idle": "2022-02-27T05:00:46.656527Z",
     "shell.execute_reply": "2022-02-27T05:00:46.655881Z",
     "shell.execute_reply.started": "2022-02-27T05:00:46.601867Z"
    },
    "id": "WeMuUVZNr9Pv"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(50, input_dim=(n_mfcc)))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense( 25, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(18, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(15, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-27T13:06:39.732724Z",
     "iopub.status.busy": "2022-02-27T13:06:39.732196Z",
     "iopub.status.idle": "2022-02-27T13:06:39.753884Z",
     "shell.execute_reply": "2022-02-27T13:06:39.753192Z",
     "shell.execute_reply.started": "2022-02-27T13:06:39.732684Z"
    }
   },
   "outputs": [],
   "source": [
    "# num_classes = 15\n",
    "# # model = SSL_Architecture().build(39, 1292,15)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='AUC')])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:09:08.049292Z",
     "iopub.status.busy": "2022-03-06T04:09:08.049012Z",
     "iopub.status.idle": "2022-03-06T04:09:08.055268Z",
     "shell.execute_reply": "2022-03-06T04:09:08.053878Z",
     "shell.execute_reply.started": "2022-03-06T04:09:08.049262Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset_generator(inputs, labels):\n",
    "    def argument_free_generator():\n",
    "        for inp, label in zip(inputs, labels):\n",
    "            yield inp, label\n",
    "    return argument_free_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:09:08.411241Z",
     "iopub.status.busy": "2022-03-06T04:09:08.410637Z",
     "iopub.status.idle": "2022-03-06T04:09:08.504255Z",
     "shell.execute_reply": "2022-03-06T04:09:08.503389Z",
     "shell.execute_reply.started": "2022-03-06T04:09:08.411175Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 27\n",
    "# Create the generator which yields inputs and outputs\n",
    "generator = create_dataset_generator(X_test,y_test.values) #to remove header from y\n",
    "\n",
    "# Create the tf.data.Dataset from this generator and specify the types and shapes of the data. \n",
    "valid_dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(n_mfcc), dtype=tf.float32), tf.TensorSpec(shape=(num_classes), dtype=tf.float32)))\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "# By default you 'run out of data', this is why you repeat the dataset and serve data in batches. \n",
    "# valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "# Create the generator which yields inputs and outputs\n",
    "generator = create_dataset_generator(X_train,y_train.values) #to remove header from y\n",
    "\n",
    "# Create the tf.data.Dataset from this generator and specify the types and shapes of the data. \n",
    "train_dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(n_mfcc), dtype=tf.float32), tf.TensorSpec(shape=(num_classes), dtype=tf.float32)))\n",
    "train_dataset = train_dataset.shuffle(buffer_size = X_train.size, seed=42)\n",
    "\n",
    "# By default you 'run out of data', this is why you repeat the dataset and serve data in batches. \n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:33:54.339425Z",
     "iopub.status.busy": "2022-03-03T16:33:54.338863Z",
     "iopub.status.idle": "2022-03-03T16:33:54.344898Z",
     "shell.execute_reply": "2022-03-03T16:33:54.344121Z",
     "shell.execute_reply.started": "2022-03-03T16:33:54.339385Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:33:54.724086Z",
     "iopub.status.busy": "2022-03-03T16:33:54.723411Z",
     "iopub.status.idle": "2022-03-03T16:33:55.682787Z",
     "shell.execute_reply": "2022-03-03T16:33:55.682033Z",
     "shell.execute_reply.started": "2022-03-03T16:33:54.724047Z"
    }
   },
   "outputs": [],
   "source": [
    "iter(train_dataset).get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:33:55.684593Z",
     "iopub.status.busy": "2022-03-03T16:33:55.684274Z",
     "iopub.status.idle": "2022-03-03T16:33:55.688631Z",
     "shell.execute_reply": "2022-03-03T16:33:55.687581Z",
     "shell.execute_reply.started": "2022-03-03T16:33:55.684553Z"
    }
   },
   "outputs": [],
   "source": [
    "# EPOCHS = 80\n",
    "# history = model.fit(train_dataset, epochs=EPOCHS, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctziq13BFXMH"
   },
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:09:13.539082Z",
     "iopub.status.busy": "2022-03-06T04:09:13.538738Z",
     "iopub.status.idle": "2022-03-06T04:09:13.565948Z",
     "shell.execute_reply": "2022-03-06T04:09:13.565015Z",
     "shell.execute_reply.started": "2022-03-06T04:09:13.539049Z"
    },
    "id": "mYpGyet0Dpe-"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam', # algo which updates weights and biases by taking loss similar to SGD(but powerful)\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy', tf.keras.metrics.AUC(name = 'AUC')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T03:31:27.809556Z",
     "iopub.status.busy": "2022-02-26T03:31:27.809056Z",
     "iopub.status.idle": "2022-02-26T03:31:27.813253Z",
     "shell.execute_reply": "2022-02-26T03:31:27.812359Z",
     "shell.execute_reply.started": "2022-02-26T03:31:27.809522Z"
    },
    "id": "oQcNXSh3boGB"
   },
   "outputs": [],
   "source": [
    "# # Create the generator which yields inputs and outputs\n",
    "# generator = create_dataset_generator(X_test,y_test.values) #to remove header from y\n",
    "\n",
    "# # Create the tf.data.Dataset from this generator and specify the types and shapes of the data. \n",
    "# train_dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(13,), dtype=tf.float32), tf.TensorSpec(shape=(15,), dtype=tf.float32)))\n",
    "\n",
    "# # By default you 'run out of data', this is why you repeat the dataset and serve data in batches. \n",
    "# train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T03:31:28.233636Z",
     "iopub.status.busy": "2022-02-26T03:31:28.233438Z",
     "iopub.status.idle": "2022-02-26T03:31:28.237253Z",
     "shell.execute_reply": "2022-02-26T03:31:28.23637Z",
     "shell.execute_reply.started": "2022-02-26T03:31:28.233612Z"
    },
    "id": "KbbwqqHFbyml"
   },
   "outputs": [],
   "source": [
    "# # Create the generator which yields inputs and outputs\n",
    "# generator = create_dataset_generator(X_train,y_train.values) #to remove header from y\n",
    "\n",
    "# # Create the tf.data.Dataset from this generator and specify the types and shapes of the data. \n",
    "# valid_dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(13,), dtype=tf.float32), tf.TensorSpec(shape=(15,), dtype=tf.float32)))\n",
    "\n",
    "# # By default you 'run out of data', this is why you repeat the dataset and serve data in batches. \n",
    "# valid_dataset = valid_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:09:18.253827Z",
     "iopub.status.busy": "2022-03-06T04:09:18.253542Z",
     "iopub.status.idle": "2022-03-06T04:16:40.761608Z",
     "shell.execute_reply": "2022-03-06T04:16:40.758699Z",
     "shell.execute_reply.started": "2022-03-06T04:09:18.253797Z"
    },
    "id": "9PClN83rFhsb",
    "outputId": "9d207285-dbe3-499d-d083-597852b3cb4f"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time_start = time.clock()\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs = 80,\n",
    "                    validation_data = valid_dataset)\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print(\"Computation time: \",time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:16:40.764459Z",
     "iopub.status.busy": "2022-03-06T04:16:40.763888Z",
     "iopub.status.idle": "2022-03-06T04:16:41.034009Z",
     "shell.execute_reply": "2022-03-06T04:16:41.033094Z",
     "shell.execute_reply.started": "2022-03-06T04:16:40.764414Z"
    },
    "id": "JWf3MYMFIbYc",
    "outputId": "92f82608-43be-4ac1-8caf-3ed722912a22"
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 80), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 80), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:16:41.036322Z",
     "iopub.status.busy": "2022-03-06T04:16:41.035702Z",
     "iopub.status.idle": "2022-03-06T04:16:41.311409Z",
     "shell.execute_reply": "2022-03-06T04:16:41.310462Z",
     "shell.execute_reply.started": "2022-03-06T04:16:41.036276Z"
    },
    "id": "I7llIt1neBkL",
    "outputId": "fc5ebc2f-7ecf-4a57-8838-ea3ab938839c"
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 80), history.history[\"accuracy\"], label=\"acc\")\n",
    "plt.plot(np.arange(0, 80), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T04:23:25.95317Z",
     "iopub.status.busy": "2022-02-25T04:23:25.952908Z",
     "iopub.status.idle": "2022-02-25T04:23:25.957977Z",
     "shell.execute_reply": "2022-02-25T04:23:25.957021Z",
     "shell.execute_reply.started": "2022-02-25T04:23:25.953139Z"
    }
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE=30\n",
    "# num_classes = 15\n",
    "# n_mfcc = 13\n",
    "\n",
    "# def create_dataset_generator(inputs, labels):\n",
    "#     def argument_free_generator():\n",
    "#         for inp, label in zip(inputs, labels):\n",
    "#             yield inp, label\n",
    "#     return argument_free_generator\n",
    "\n",
    "# # Create the generator which yields inputs and outputs\n",
    "# generator = create_dataset_generator(X, y.values) #to remove header from y\n",
    "\n",
    "# # Create the tf.data.Dataset from this generator and specify the types and shapes of the data. \n",
    "# train_dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(n_mfcc,), dtype=tf.float32), tf.TensorSpec(shape=(num_classes,), dtype=tf.float32)))\n",
    "\n",
    "# # By default you 'run out of data', this is why you repeat the dataset and serve data in batches. \n",
    "# train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "# print(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:34:13.802446Z",
     "iopub.status.busy": "2022-03-03T16:34:13.802152Z",
     "iopub.status.idle": "2022-03-03T16:34:13.807438Z",
     "shell.execute_reply": "2022-03-03T16:34:13.806717Z",
     "shell.execute_reply.started": "2022-03-03T16:34:13.802413Z"
    }
   },
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def ramp_up_function(epoch, epoch_with_max_rampup=80):\n",
    "    \"\"\" Ramps the value of the weight and learning rate according to the epoch\n",
    "        according to the paper\n",
    "    Arguments:\n",
    "        {int} epoch\n",
    "        {int} epoch where the rampup function gets its maximum value\n",
    "    Returns:\n",
    "        {float} -- rampup value\n",
    "    \"\"\"\n",
    "\n",
    "    if epoch < epoch_with_max_rampup:\n",
    "        p = max(0.0, float(epoch)) / float(epoch_with_max_rampup)\n",
    "        p = 1.0 - p\n",
    "        return math.exp(-p*p*5.0)\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:31:01.220225Z",
     "iopub.status.busy": "2022-03-03T16:31:01.219953Z",
     "iopub.status.idle": "2022-03-03T16:31:01.224128Z",
     "shell.execute_reply": "2022-03-03T16:31:01.223473Z",
     "shell.execute_reply.started": "2022-03-03T16:31:01.220188Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:34:32.121004Z",
     "iopub.status.busy": "2022-03-03T16:34:32.12065Z",
     "iopub.status.idle": "2022-03-03T16:34:32.134975Z",
     "shell.execute_reply": "2022-03-03T16:34:32.134294Z",
     "shell.execute_reply.started": "2022-03-03T16:34:32.120881Z"
    },
    "id": "oWdZMPqQr9Pv"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def loss(model, X, y, B, C, z, w, training):\n",
    "    \n",
    "    # training=training is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    y_pred = model(X, training=False)\n",
    "#     print(\"y_pred: \",y_pred)\n",
    "#     print(\"\\nz: \",z.size)\n",
    "    # print(\"\\nlabel: \",y)\n",
    "#     print(\"y \",y.shape)\n",
    "#     print(\"ypred \",y_pred.shape)\n",
    "    supervised_loss = cross_entropy(y_true=y, y_pred=y_pred)/B\n",
    "#     print(\"Sup loss: \",supervised_loss)\n",
    "    \n",
    "    \n",
    "    unsupervised_loss = mse(y_pred, z)/(B*C)\n",
    "    unsupervised_loss = tf.cast(unsupervised_loss, tf.float32)\n",
    "#     print(\"Unsup: \",unsupervised_loss)\n",
    "#     print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    loss = supervised_loss + w*unsupervised_loss\n",
    "#     print( \"total loss: \",loss)\n",
    "    # print(\"=\"*70)\n",
    "    # print(\"\\n\")\n",
    "    return loss, y_pred\n",
    "\n",
    "def grad(model, X, y, B, C, z, w):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value, y_pred = loss(model, X, y, B, C, z, w, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables), y_pred\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002) # 0.001 as recomended in the paper leads to unstable training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-03T16:34:50.97852Z",
     "iopub.status.busy": "2022-03-03T16:34:50.97827Z",
     "iopub.status.idle": "2022-03-03T16:39:39.672037Z",
     "shell.execute_reply": "2022-03-03T16:39:39.671032Z",
     "shell.execute_reply.started": "2022-03-03T16:34:50.978493Z"
    },
    "id": "cY4kmKgOr9Pv",
    "outputId": "1dc5334d-c284-482b-e3ef-3809834fe193"
   },
   "outputs": [],
   "source": [
    "## Note: Rerunning this cell uses the same model variable\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "N = X_train.size\n",
    "num_labeled_samples = X_labelled.size\n",
    "NUM_TRAIN_SAMPLES = X_train.size\n",
    "\n",
    "# Hyperparameters\n",
    "z = np.zeros((BATCH_SIZE,num_classes))\n",
    "Z = np.zeros((BATCH_SIZE,num_classes))\n",
    "max_unsupervised_weight = 30 * num_labeled_samples / NUM_TRAIN_SAMPLES\n",
    "alpha = 0.6\n",
    "unsupervised_weight = 0\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "NUM_EPOCHS = 80\n",
    "time_start = time.clock()\n",
    "\n",
    "for epoch in range(1,NUM_EPOCHS+1):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    rampup_value = ramp_up_function(epoch, 30)\n",
    "    if epoch == 0:\n",
    "        unsupervised_weight = 0\n",
    "    else:\n",
    "        unsupervised_weight = max_unsupervised_weight * rampup_value\n",
    "            \n",
    "    # Training loop - using batches of 10\n",
    "    for x, y_ in train_dataset:\n",
    "        # Optimize the model\n",
    "        loss_value, grads, y_pred = grad(model, x, y_, BATCH_SIZE, num_classes, z, unsupervised_weight)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # print(\"TYPE: \",tf.shape(y), tf.shape(y_pred))\n",
    "        # Track progress\n",
    "        epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        # training=True is needed only if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        x_test, y_test = iter(valid_dataset).get_next()\n",
    "#         print(x_test.shape, y_test.shape)\n",
    "        epoch_accuracy.update_state(y_test, model(x_test, training=False))\n",
    "\n",
    "    # Increment w and update z,Z\n",
    "    Z = alpha*Z + (1-alpha)*y_pred\n",
    "    z = Z/(1 - pow(alpha, epoch))\n",
    "    \n",
    "#     print(\"y pred \",y_pred)\n",
    "#     print(\"ALPHAAAAAA \",alpha)\n",
    "#     print(Z)\n",
    "#     print(z)\n",
    "    # End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result()*10)\n",
    "#     print(acc)\n",
    "    print(\"Epoch {:03d}: Average loss: {:.3f} Average accuracy: {:.3f}\".format(epoch,epoch_loss_avg.result(),epoch_accuracy.result()))\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print(\"Computation time: \",time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-03T16:39:39.673231Z",
     "iopub.status.idle": "2022-03-03T16:39:39.673812Z",
     "shell.execute_reply": "2022-03-03T16:39:39.673595Z",
     "shell.execute_reply.started": "2022-03-03T16:39:39.673567Z"
    },
    "id": "1TTvZ5_rr9Pw",
    "outputId": "62e966b4-460a-4972-d7a0-f2db4ac4d251"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epoch), train_loss_results, label=\"train_loss\")\n",
    "plt.title(\"Average epoch Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-03T16:39:39.674974Z",
     "iopub.status.idle": "2022-03-03T16:39:39.675543Z",
     "shell.execute_reply": "2022-03-03T16:39:39.675326Z",
     "shell.execute_reply.started": "2022-03-03T16:39:39.675298Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epoch), train_accuracy_results, label=\"train_accuracy\")\n",
    "plt.title(\"Average epoch accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T12:20:31.673974Z",
     "iopub.status.busy": "2022-01-18T12:20:31.673315Z",
     "iopub.status.idle": "2022-01-18T12:20:31.698801Z",
     "shell.execute_reply": "2022-01-18T12:20:31.698125Z",
     "shell.execute_reply.started": "2022-01-18T12:20:31.673924Z"
    },
    "id": "OFO-b1XJXVWx"
   },
   "outputs": [],
   "source": [
    "# Create the generator which yields inputs and outputs\n",
    "generator = create_dataset_generator(X, y_labels.values) #to remove header from y\n",
    "\n",
    "# Create the tf.data.Dataset from this generator and specify the types and shapes of the data. \n",
    "train_dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(13,), dtype=tf.float32), tf.TensorSpec(shape=(15,), dtype=tf.float32)))\n",
    "\n",
    "# By default you 'run out of data', this is why you repeat the dataset and serve data in batches. \n",
    "train = train_dataset.batch(1170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNdRVqAZX6kX"
   },
   "outputs": [],
   "source": [
    "for x,y in train:\n",
    "  y_pred = model.predict(x)\n",
    "  y_labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veMN9T_hZLin",
    "outputId": "d6d667bc-3040-4ca7-b4dd-616d512c6d48"
   },
   "outputs": [],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tgg0H5V4Z0Eg",
    "outputId": "0cd098f5-313e-4d1e-a2dd-1045adf24475"
   },
   "outputs": [],
   "source": [
    "np.argmax(y_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_XHvR8OjWji"
   },
   "outputs": [],
   "source": [
    "y_pred = y_labels\n",
    "import random\n",
    "idx = random.sample(range(0,1170), 300)\n",
    "idx\n",
    "for id in idx:\n",
    "  y_pred[id] = random.randint(0,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3g15xS4YMvXs",
    "outputId": "63e0da0b-9a8d-4f70-e344-d9a101138dbc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "# y_pred=np.argmax(y_pred, axis=1)\n",
    "# y_labels=np.argmax(y_labels, axis=1)\n",
    "cf_matrix = confusion_matrix(y_labels, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJNmVHt2SRZ-",
    "outputId": "3a5dc48c-15db-4920-e387-93f89304e652"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6-_JIgjaW1s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
